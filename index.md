---
title: Challenge Description
feature_text: |
  ## Short-duration Speaker Verification (SdSV) Challenge 2020
  Evaluate New Technologies in Short Duration Senarios
feature_image: "https://picsum.photos/1300/400?image=866"
excerpt: "A Short Description of SdSV Challenge 2020"
aside: True
---

## Welcome to SdSV Challenge 2020! 

The main goal of the SdSV Challenge 2020 is to evaluate new technologies for text-dependent (TD) and text-independent (TI) speaker verification (SV) in short duration scenario.

The challenge evaluates SdSV with varying degree of phonetic overlap between the enrollment and test utterances. It is the first challenge with a broad focus on systematic benchmark and analysis on varying degree of phonetic variability on short-duration speaker recognition.

The evaluation dataset used for the challenge is drawn from the recently released multi-purpose DeepMine dataset[1]. The dataset has three parts and among them Part 1 is used for TD-SV while Part 3 is for TI-SV.

[1] H. Zeinali, L. Burget, J. Cernocky, A multi purpose and large scale speech corpus in Persian and English for speaker and speech recognition:  the DeepMine database, in:  Proc. ASRU 2019 The 2019 IEEE Automatic Speech Recognition and Understanding Workshop, 2019 (2019).

The Kaldi baseline recipe for both tasks can be found in [this link](/assets/sdsvc2020_kaldi_xvector_baseline.tar.gz). For running the baseline you should first download both VoxCeleb1 and VoxCeleb2 datasets. Then after downloading the challenge data, by putting the baseline code in the Kaldi egs directory you can run this code.

The full challenge evaluation plane version 1.1 can be found in [this link](/assets/SdSV_Challenge_Evaluation_Plan.pdf). If you have any more questions regarding the challenge you can contact organizers via [sdsvc2020\[at\]gmail.com](mailto:sdsvc2020\[at\]gmail.com).

---
### Schedule[modified]
<table border="0">
 <tr>
    <td>
    January 10, 2020
    </td>
    <td>
    Release of evaluation plan
    </td>
 </tr>
 <tr>
    <td>
    January 15, 2020
    </td>
    <td>
    Evaluation platform open
    </td>
 </tr>
 <tr>
    <td>
    January 10, 2020
    </td>
    <td>
    Release of train, development and evaluation sets
    </td>
 </tr>
 <tr>
    <td>
    April 17, 2020 
    </td>
    <td>
    Challenge deadline
    </td>
 </tr>
 <tr>
    <td>
    April 27, 2020 
    </td>
    <td>
    Release of results
    </td>
 </tr>
 <tr>
    <td>
    October 25, 2020
    </td>
    <td>
    Post-challenge evaluation
    </td>
 </tr>
 <tr>
    <td>
    May 8, 2020 
    </td>
    <td>
    Interspeech submission deadline
    </td>
 </tr>
 <tr>
    <td>
    October 25-29, 2020
    </td>
    <td>
    SdSV Challenge 2020 special session at Interspeech
    </td>
 </tr>
 <tr><td> &nbsp; </td></tr>
</table>


---
### Prizes
There will be three cash prizes for each task. The winners will be selected based on the results of the primary systems on the evaluation subset. In addition to the cash prize, each winner will receive a certificate for their achievement. The cash prizes are as follow:
- Rank 1: 500 EUR
- Rank 2: 300 EUR
- Rank 3: 100 EUR

---
### Sponsors
<table border="0">
 <tr>
    <td>
	<a href="http://deepmine.ir/">Sharif DeepMine Ltd.</a> 
    </td>
    <td>
	<a href="http://deepmine.ir/"><img align="right" width="120" src="/images/deepmine.jpg"></a>
    </td>
 </tr>
 <tr>
    <td>
    <a href="https://www.crim.ca/en">Computer Research Institute of Montreal (CRIM)</a>
    </td>
    <td style="padding-bottom: 15px; padding-top: 15px;">
    <a href="https://www.crim.ca/en"><img align="right" width="220" src="/images/logo_CRIM_300dpi.jpg"></a>
    </td>
 </tr>
 <tr>
    <td>
    <a href="https://www.phonexia.com">Phonexia Ltd.</a>
    </td>
    <td>
    <a href="https://www.phonexia.com"><img align="right" width="220" src="/images/phonexia2.png"></a>
    </td>
 </tr>
</table>




















